# Configuration file for ML-IMC

[global]
# Input files with system configurations
system_files = [
    # 10
    # "configs/methanol-data/10CH3OH/10CH3OH-CG.toml",
    # "configs/methanol-data/10CH3OH/10CH3OH-CG-2.toml",
    # 40
    "configs/methanol-data/40CH3OH/40CH3OH-CG.toml",
    # "configs/methanol-data/40CH3OH/40CH3OH-CG-2.toml",
    # 60
    # "configs/methanol-data/60CH3OH/60CH3OH-CG.toml",
    # "configs/methanol-data/60CH3OH/60CH3OH-CG-2.toml",
    # 70
    # "configs/methanol-data/70CH3OH/70CH3OH-CG.toml",
    # "configs/methanol-data/70CH3OH/70CH3OH-CG-2.toml",
    # 100
    # "configs/methanol-data/100CH3OH/100CH3OH-CG.toml",
    # "configs/methanol-data/100CH3OH/100CH3OH-CG-2.toml",
]

# File defining the symmetry functions for atomic descriptors.
symmetry_function_file = "configs/methanol-data/symmetry_functions.toml" 

# Operation mode: "training" to train the NN, or "simulation" to run an MC simulation with a trained model.
mode = "training"

# Output detail level: "default" shows RDFs and Energies, "verbose" also writes trajectory files.
output_mode = "default"

# Model and optimization file paths
model_file = "none"      # Path to a pre-trained model. "none" => random initialization.
gradients_file = "none"  # Path to pre-calculated gradients. "none" => default initialization.
optimizer_file = "none"  # Path to saved optimizer state. "none" => default state.
adaptive_scaling = false # true => adapt gradient scaling per system; false => uniform averaging.

[monte_carlo]
# Monte Carlo simulation parameters
steps = 3060000                   # Total number of MC steps to run.
equilibration_steps = 60000       # MC steps for equilibration before data collection.
step_adjust_frequency = 600       # Adjust max MC displacement every N steps to maintain acceptance rate.
trajectory_output_frequency = 600 # Write system configuration to trajectory file every N steps. (Only in verbose mode)
output_frequency = 600            # Sampling frequency for system states and energy recording.
                                  # Recommended to be slightly above system size N.

[neural_network]
# Neural network architecture
neurons = [64, 64, 64, 64, 64, 1]   # Neurons per layer (output included). Input equals number of symmetry functions.
bias = true                         # Whether to use bias in each layer.
# Activation function for each layer.
activations = ["identity", "leakyrelu", "leakyrelu", "leakyrelu", "leakyrelu", "identity"] 


# Training hyperparameters
iterations = 10            # Number of training iterations.
regularization = 0.0       # L2 regularization coefficient (0.0 = disabled).

# Optimizer configuration
optimizer = "Adam"         # Recommended: "Adam", "AMSGrad", "AdamW"
learning_rate = 0.0001     # Optimizer learning rate.
momentum = 0.9             # Momentum factor (used in Adam-based optimizers).
decay_rates = [0.9, 0.999] # Exponential decay for first & second moment estimates.

[pretraining]
# Pre-training settings
steps = 20000              # Number of MC steps for neural network pre-training.
batch_size = 10            # Initial Batch Size for pre-training.
output_frequency = 1       # Report progress every N steps during pre-training.
regularization = 0.0       # L2 regularization (0.0 = disabled) for pre-training.

# Pre-training optimizer settings
optimizer = "Adam"         # Optimizer type for pre-training.
learning_rate = 0.01       # Learning rate during pre-training.
momentum = 0.9             # Momentum factor during pre-training.
decay_rates = [0.9, 0.999] # Decay parameters for first/second moments during pre-training.
